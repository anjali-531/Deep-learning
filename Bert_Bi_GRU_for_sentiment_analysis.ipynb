{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Bi-GRU for sentiment analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a6a17cf3aba848d1bddc901ae0864765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c79bc580103b48ebabaf6a7a40e35b46",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f780c5120ab44278047ef8cf4b632e1",
              "IPY_MODEL_d7928168ccdc4dc08a82af8570433861"
            ]
          }
        },
        "c79bc580103b48ebabaf6a7a40e35b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f780c5120ab44278047ef8cf4b632e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_99689d002e1d4a99b05911771e71ff8f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_406d8bda98324a4f843fb94df86d0fee"
          }
        },
        "d7928168ccdc4dc08a82af8570433861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e62ed20ee446467897b50981cf08f1ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 759kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53f4b544e72e461babb20e38cf6d6893"
          }
        },
        "99689d002e1d4a99b05911771e71ff8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "406d8bda98324a4f843fb94df86d0fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e62ed20ee446467897b50981cf08f1ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53f4b544e72e461babb20e38cf6d6893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a06609ad171c442a91f6a154cb544b09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7110543f0bc467a9f6ab6e50ad236dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f01f824b27cd4e55a8bb02e79f434cca",
              "IPY_MODEL_f49959badc0f4b8ba2f34e06147067f1"
            ]
          }
        },
        "c7110543f0bc467a9f6ab6e50ad236dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f01f824b27cd4e55a8bb02e79f434cca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_338b50d9d4db4e31b30e4624fc007875",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df120c63ed764304b9a3e7dd4c29d6d1"
          }
        },
        "f49959badc0f4b8ba2f34e06147067f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf47dccadd1c4902baf37e6e617c7bc8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.44kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3ed6b1e8ace4fe99b2e3a9bc9152cd0"
          }
        },
        "338b50d9d4db4e31b30e4624fc007875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df120c63ed764304b9a3e7dd4c29d6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf47dccadd1c4902baf37e6e617c7bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3ed6b1e8ace4fe99b2e3a9bc9152cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f156765a3684fb5ac69fd69fe3ca102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_374d4e30cbee4b45b0c9d64b0853f468",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_971168f720824900b811ef71aeab5d2c",
              "IPY_MODEL_c505014e36cd49e28ad40145a78f4c98"
            ]
          }
        },
        "374d4e30cbee4b45b0c9d64b0853f468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "971168f720824900b811ef71aeab5d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_235ebfbbf1b54622949ecec41eee2ba2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fc9e362f5b34cfe9d2f04316921b318"
          }
        },
        "c505014e36cd49e28ad40145a78f4c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_783083441dc84840b5d381dd94f04226",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [01:20&lt;00:00, 5.51MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd70d00592f14fd3987ffb2508e52469"
          }
        },
        "235ebfbbf1b54622949ecec41eee2ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fc9e362f5b34cfe9d2f04316921b318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "783083441dc84840b5d381dd94f04226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd70d00592f14fd3987ffb2508e52469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWL1_n9UZzpr",
        "colab_type": "text"
      },
      "source": [
        "##Bert Bi-GRU for sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkERqkeEOoon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch #pytorch library\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED) #setting random seed\n",
        "np.random.seed(SEED) #setting \n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIFwzu1YO2cD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "0ab03fa1-1809-48a7-8761-9677b3507190"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 23.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 31.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 58.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=5581a4e5b1410261cec5025b100a34d2883476ac4a3bde9d9eb2412659dc47ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arugvFY2OrbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "a6a17cf3aba848d1bddc901ae0864765",
            "c79bc580103b48ebabaf6a7a40e35b46",
            "6f780c5120ab44278047ef8cf4b632e1",
            "d7928168ccdc4dc08a82af8570433861",
            "99689d002e1d4a99b05911771e71ff8f",
            "406d8bda98324a4f843fb94df86d0fee",
            "e62ed20ee446467897b50981cf08f1ca",
            "53f4b544e72e461babb20e38cf6d6893"
          ]
        },
        "outputId": "3202258c-401f-45bf-fb41-b0e0c23c4408"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "#loading the pre-trained bert-base-uncased tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6a17cf3aba848d1bddc901ae0864765",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52oBRobMO0gs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77e17664-71c3-4d1e-a817-488aac9e534c"
      },
      "source": [
        "#checking number of tokens in BERT vocabulary\n",
        "len(tokenizer.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p8d6o2KO-VQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2284bba0-3989-427e-8763-36644a958d2e"
      },
      "source": [
        "#tokenizing using bert tokenizer\n",
        "tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hello', 'world', 'how', 'are', 'you', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK90qNMNPBZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13159791-ea87-4f20-a485-f06241fa7c56"
      },
      "source": [
        "#numericalizing tokens\n",
        "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(indexes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7592, 2088, 2129, 2024, 2017, 1029]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJqFiTP8PEIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f4de14d-cfef-476f-bad9-3c1f82763d74"
      },
      "source": [
        "init_token = tokenizer.cls_token # first token of the sequence \n",
        "eos_token = tokenizer.sep_token # last token of a sequence \n",
        "pad_token = tokenizer.pad_token # token used for padding\n",
        "unk_token = tokenizer.unk_token # unknown token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73pmmogFPGWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24e1004b-944a-4488-f1fe-4c104b9e9f43"
      },
      "source": [
        "# the indexes of the special tokens by converting them using the vocabulary\n",
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)\n",
        "\n",
        "# or we can get these indexes by explicitly getting them from the tokenizer.\n",
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHTTIhkEPK91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60865ef0-dbe3-4dc5-9a23-2b01b212570d"
      },
      "source": [
        "# the model was trained on sequences with a defined maximum length. \n",
        "# Getting this maximum length.\n",
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcSqv3_dPNeJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making our own tokenizing function that tokenizes sentences and cuts them to a \n",
        "# size (max_input_length - 2) \n",
        "def tokenize_and_cut(sentence):\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpVlsAOmPPzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import data\n",
        "#creating preprocessing pipelines for text and label columns\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = tokenize_and_cut,\n",
        "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQQUitIDPR9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "60046150-581c-4778-c25b-42e07d14fc5e"
      },
      "source": [
        "#importing dataset\n",
        "from torchtext import datasets\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "#splitting train_data to train data and valid data\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   0%|          | 98.3k/84.1M [00:00<01:33, 899kB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 28.9MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFHR5BRjPT_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "88346486-da31-4011-ead5-b6aa8799374f"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIM0z2wtPWSj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "974dfd81-8de9-4c8d-dbe2-9cc818d5f1eb"
      },
      "source": [
        "print(vars(train_data.examples[6]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': [2619, 2182, 2941, 4102, 2023, 3185, 1999, 2070, 3971, 2000, 2152, 11501, 1012, 2085, 2008, 2003, 1037, 2613, 7683, 999, 1045, 1005, 1049, 1037, 2502, 19643, 5470, 2164, 2070, 1997, 2010, 3772, 4395, 2021, 2672, 1996, 2069, 2711, 2040, 2071, 2031, 2209, 2023, 2112, 2052, 2031, 2042, 2123, 12226, 3215, 1012, 2034, 2125, 1010, 2004, 2619, 4197, 2041, 1010, 19643, 2074, 2987, 1005, 1056, 2031, 1996, 3857, 2005, 1037, 2530, 2919, 1011, 3124, 10587, 4783, 1012, 2002, 1005, 1055, 2074, 2205, 1005, 7263, 1005, 2012, 2023, 2391, 1999, 2010, 2166, 1012, 2672, 2002, 2001, 2055, 1996, 2168, 4578, 2004, 2360, 20075, 2063, 7104, 1010, 2021, 7104, 2018, 1037, 3492, 5024, 3857, 1012, 19643, 3310, 2408, 2004, 1996, 2502, 3331, 2210, 4845, 2040, 6343, 11276, 2000, 2202, 5667, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 2466, 2003, 4895, 7076, 21649, 1998, 2428, 2025, 23411, 1012, 1045, 2123, 1005, 1056, 2215, 2000, 27594, 2009, 2021, 1045, 2228, 1996, 4566, 1998, 2129, 1996, 27938, 10509, 1999, 2023, 2466, 2987, 1005, 1056, 2191, 2151, 3168, 1012, 2178, 2518, 1010, 2122, 2111, 7887, 3499, 3209, 2000, 2022, 3294, 2935, 2098, 2058, 2011, 2070, 1005, 2919, 3124, 1005, 1012, 2023, 2003, 2074, 1037, 2210, 2237, 1010, 2061, 1045, 2123, 1005, 1056, 2131, 1996, 8432, 4496, 2079, 1045, 3305, 2339, 1996, 2111, 2052, 2292, 3209, 2022, 6817, 2008, 2126, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2045, 2003, 1037, 1005, 2293, 3037, 1005, 1999, 1996, 2466, 1998, 2065, 1045, 2628, 2009, 2157, 1010, 2016, 2001, 6314, 2043, 1996, 2364, 2839, 4188, 2000, 6449, 2040, 2002, 2001, 2061, 2070, 2060, 2919, 3124, 2876, 1005, 1056, 3102, 2032, 1012, 2085, 2045, 1005, 1055, 2995, 2293, 2005, 2017, 1012, 1005, 3233, 2039, 2005, 4426, 999, 2425, 2032, 2115, 2171, 2061, 2002, 2097, 3102, 2017, 999, 1005, 8840, 2140, 1012, 2644, 1010, 2017, 1005, 2128, 4288, 2033, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 6854, 1996, 3937, 18458, 1997, 1996, 3185, 3475, 1005, 1056, 2204, 2438, 1998, 2053, 3043, 2129, 2027, 2699, 2023, 2466, 2134, 1005, 1056, 2031, 1037, 11177, 4130, 2000, 3582, 2060, 2084, 2046, 1996, 5949, 25351, 1012, 2215, 2000, 2113, 2339, 2009, 1005, 1055, 2025, 2006, 2678, 1998, 2196, 3491, 2006, 2694, 1029, 1996, 4401, 4593, 6090, 7228, 2009, 1999, 3838, 1998, 2027, 2020, 2157, 1011, 2023, 3185, 2003, 3492, 2919, 1012, 1045, 2052, 2471, 6655, 19643, 3825, 2619, 2000, 2784, 2416, 1996, 2518, 2004, 2172, 2004, 2825, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2017, 2215, 2000, 2156, 1037, 2204, 2530, 2073, 1037, 2237, 4832, 2039, 2114, 1037, 2919, 3124, 1029, 3046, 6980, 2012, 2795, 2600, 1010, 2030, 2012, 3282, 8400, 1011, 2048, 2428, 1010, 2428, 2204, 2530, 2015, 2007, 2008, 4323, 1012, 5206, 9530, 9905, 2003, 5206, 27136, 2080, 1012, 3581, 1010, 2017, 2020, 1996, 4602, 3220, 2412, 1011, 2021, 2017, 2134, 1005, 1056, 7141, 1999, 1037, 3185, 2066, 2023, 1012], 'label': 'neg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0zP7to_Pb5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4950b0b1-33c0-4b2c-9b75-fcedfb5a387f"
      },
      "source": [
        "# getting sentence from list of indexes\n",
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6])['text'])\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['someone', 'here', 'actually', 'compared', 'this', 'movie', 'in', 'some', 'ways', 'to', 'high', 'noon', '.', 'now', 'that', 'is', 'a', 'real', 'stretch', '!', 'i', \"'\", 'm', 'a', 'big', 'sinatra', 'fan', 'including', 'some', 'of', 'his', 'acting', 'roles', 'but', 'maybe', 'the', 'only', 'person', 'who', 'could', 'have', 'played', 'this', 'part', 'would', 'have', 'been', 'don', 'knot', '##ts', '.', 'first', 'off', ',', 'as', 'someone', 'pointed', 'out', ',', 'sinatra', 'just', 'doesn', \"'\", 't', 'have', 'the', 'build', 'for', 'a', 'western', 'bad', '-', 'guy', 'wanna', '##be', '.', 'he', \"'\", 's', 'just', 'too', \"'\", 'slight', \"'\", 'at', 'this', 'point', 'in', 'his', 'life', '.', 'maybe', 'he', 'was', 'about', 'the', 'same', 'height', 'as', 'say', 'audi', '##e', 'murphy', ',', 'but', 'murphy', 'had', 'a', 'pretty', 'solid', 'build', '.', 'sinatra', 'comes', 'across', 'as', 'the', 'big', 'talking', 'little', 'kid', 'who', 'nobody', 'ought', 'to', 'take', 'seriously', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'story', 'is', 'un', '##ins', '##pired', 'and', 'really', 'not', 'credible', '.', 'i', 'don', \"'\", 't', 'want', 'to', 'spoil', 'it', 'but', 'i', 'think', 'the', 'ending', 'and', 'how', 'the', 'townspeople', 'react', 'in', 'this', 'story', 'doesn', \"'\", 't', 'make', 'any', 'sense', '.', 'another', 'thing', ',', 'these', 'people', 'constantly', 'allow', 'themselves', 'to', 'be', 'completely', 'lord', '##ed', 'over', 'by', 'some', \"'\", 'bad', 'guy', \"'\", '.', 'this', 'is', 'just', 'a', 'little', 'town', ',', 'so', 'i', 'don', \"'\", 't', 'get', 'the', 'attraction', 'nor', 'do', 'i', 'understand', 'why', 'the', 'people', 'would', 'let', 'themselves', 'be', 'dominated', 'that', 'way', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'there', 'is', 'a', \"'\", 'love', 'interest', \"'\", 'in', 'the', 'story', 'and', 'if', 'i', 'followed', 'it', 'right', ',', 'she', 'was', 'upset', 'when', 'the', 'main', 'character', 'refused', 'to', 'admit', 'who', 'he', 'was', 'so', 'some', 'other', 'bad', 'guy', 'wouldn', \"'\", 't', 'kill', 'him', '.', 'now', 'there', \"'\", 's', 'true', 'love', 'for', 'you', '.', \"'\", 'stand', 'up', 'for', 'yourself', '!', 'tell', 'him', 'your', 'name', 'so', 'he', 'will', 'kill', 'you', '!', \"'\", 'lo', '##l', '.', 'stop', ',', 'you', \"'\", 're', 'killing', 'me', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'unfortunately', 'the', 'basic', 'premise', 'of', 'the', 'movie', 'isn', \"'\", 't', 'good', 'enough', 'and', 'no', 'matter', 'how', 'they', 'tried', 'this', 'story', 'didn', \"'\", 't', 'have', 'a', 'logical', 'path', 'to', 'follow', 'other', 'than', 'into', 'the', 'waste', '##basket', '.', 'want', 'to', 'know', 'why', 'it', \"'\", 's', 'not', 'on', 'video', 'and', 'never', 'shown', 'on', 'tv', '?', 'the', 'critics', 'apparently', 'pan', '##ned', 'it', 'in', '1956', 'and', 'they', 'were', 'right', '-', 'this', 'movie', 'is', 'pretty', 'bad', '.', 'i', 'would', 'almost', 'bet', 'sinatra', 'paid', 'someone', 'to', 'deep', 'six', 'the', 'thing', 'as', 'much', 'as', 'possible', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'you', 'want', 'to', 'see', 'a', 'good', 'western', 'where', 'a', 'town', 'stands', 'up', 'against', 'a', 'bad', 'guy', '?', 'try', 'tension', 'at', 'table', 'rock', ',', 'or', 'at', 'gun', '##point', '-', 'two', 'really', ',', 'really', 'good', 'western', '##s', 'with', 'that', 'theme', '.', 'johnny', 'con', '##cho', 'is', 'johnny', 'stink', '##o', '.', 'frank', ',', 'you', 'were', 'the', 'greatest', 'singer', 'ever', '-', 'but', 'you', 'didn', \"'\", 't', 'belong', 'in', 'a', 'movie', 'like', 'this', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YznNfHAzPex-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#building label vocabulary\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pAdYrOWPgqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6b28203-d892-4449-c27c-db5b09d7a682"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fb6216c0268>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkcJAtDFQpnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating iterator for train, valid and test data\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUY8ZHsoPits",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "a06609ad171c442a91f6a154cb544b09",
            "c7110543f0bc467a9f6ab6e50ad236dc",
            "f01f824b27cd4e55a8bb02e79f434cca",
            "f49959badc0f4b8ba2f34e06147067f1",
            "338b50d9d4db4e31b30e4624fc007875",
            "df120c63ed764304b9a3e7dd4c29d6d1",
            "cf47dccadd1c4902baf37e6e617c7bc8",
            "f3ed6b1e8ace4fe99b2e3a9bc9152cd0",
            "1f156765a3684fb5ac69fd69fe3ca102",
            "374d4e30cbee4b45b0c9d64b0853f468",
            "971168f720824900b811ef71aeab5d2c",
            "c505014e36cd49e28ad40145a78f4c98",
            "235ebfbbf1b54622949ecec41eee2ba2",
            "3fc9e362f5b34cfe9d2f04316921b318",
            "783083441dc84840b5d381dd94f04226",
            "bd70d00592f14fd3987ffb2508e52469"
          ]
        },
        "outputId": "6cb46c39-b006-4b2e-deb4-059487c0ac1f"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "#importing the pretrained bert model\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a06609ad171c442a91f6a154cb544b09",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f156765a3684fb5ac69fd69fe3ca102",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxYRTA7Rqvvb",
        "colab_type": "text"
      },
      "source": [
        "Building our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FikLSMh1Pluo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        #we use bert pretrained embeddings\n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        #defining our GRU layer \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        #defining fully connected layer\n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        #defining dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            # The transformer returns the embeddings for the whole sequence \n",
        "            # as well as a pooled output. We require the embeddings\n",
        "            embedded = self.bert(text)[0]\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t72ZFMWAP3xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining hyperparameters\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "# creating the model instance\n",
        "model = BERTGRUSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSX-MSX_P71D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49b19e3d-9f1a-47a6-f16a-f8bec79592b8"
      },
      "source": [
        "#getting the number of parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 112,241,409 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzGT-ubZP-lW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we set the requires_grad to false for all the bert parameters because they are pre trained\n",
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqj_OjmdQA27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "500607a1-2871-4c66-d0f2-95b427f760a3"
      },
      "source": [
        "#this reduces our number of trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,759,169 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbxcNFrWQL8n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "8e63cfdf-c2a3-4f44-cf47-d2f50e5a829e"
      },
      "source": [
        "# checking the names of the trainable parameters, ensuring they make sense. \n",
        "# As we can see, they are all the parameters of the GRU (rnn) and the linear layer (out).\n",
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Pkk9JvQOTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing optim library to define our optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHS5hzqNQQ8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining our loss function\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpppJNd8QS-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# putting model and criterion to device\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzM1kIlhsbVT",
        "colab_type": "text"
      },
      "source": [
        "Training our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgFuoBU7QVqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining our accuracy function\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdEI9gEbQxGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \"\"\" training our model\"\"\"    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxP3l5RRQ0JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \"\"\" evaluating our model on validation dataset\"\"\"    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlQ9D2eRQ2iR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    \"\"\"calculating how long a training/evaluation epoch takes\"\"\"\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzIyXgDUQ4y1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c3f4c45-cd0b-4339-9cbb-d32ce3fcc4b8"
      },
      "source": [
        "#training our model\n",
        "N_EPOCHS = 20\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "        \n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    # saving the models which have better valid_loss    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.495 | Train Acc: 75.14%\n",
            "\t Val. Loss: 0.299 |  Val. Acc: 87.67%\n",
            "Epoch: 02 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.287 | Train Acc: 88.35%\n",
            "\t Val. Loss: 0.245 |  Val. Acc: 90.21%\n",
            "Epoch: 03 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.235 | Train Acc: 90.58%\n",
            "\t Val. Loss: 0.227 |  Val. Acc: 90.90%\n",
            "Epoch: 04 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.219 | Train Acc: 91.46%\n",
            "\t Val. Loss: 0.220 |  Val. Acc: 91.49%\n",
            "Epoch: 05 | Epoch Time: 7m 5s\n",
            "\tTrain Loss: 0.183 | Train Acc: 93.17%\n",
            "\t Val. Loss: 0.232 |  Val. Acc: 90.89%\n",
            "Epoch: 06 | Epoch Time: 7m 6s\n",
            "\tTrain Loss: 0.162 | Train Acc: 93.80%\n",
            "\t Val. Loss: 0.251 |  Val. Acc: 90.72%\n",
            "Epoch: 07 | Epoch Time: 7m 6s\n",
            "\tTrain Loss: 0.131 | Train Acc: 95.13%\n",
            "\t Val. Loss: 0.248 |  Val. Acc: 91.89%\n",
            "Epoch: 08 | Epoch Time: 7m 7s\n",
            "\tTrain Loss: 0.110 | Train Acc: 95.94%\n",
            "\t Val. Loss: 0.268 |  Val. Acc: 91.37%\n",
            "Epoch: 09 | Epoch Time: 7m 7s\n",
            "\tTrain Loss: 0.083 | Train Acc: 97.01%\n",
            "\t Val. Loss: 0.309 |  Val. Acc: 90.99%\n",
            "Epoch: 10 | Epoch Time: 7m 7s\n",
            "\tTrain Loss: 0.068 | Train Acc: 97.56%\n",
            "\t Val. Loss: 0.277 |  Val. Acc: 91.50%\n",
            "Epoch: 11 | Epoch Time: 7m 6s\n",
            "\tTrain Loss: 0.058 | Train Acc: 97.89%\n",
            "\t Val. Loss: 0.278 |  Val. Acc: 91.49%\n",
            "Epoch: 12 | Epoch Time: 7m 7s\n",
            "\tTrain Loss: 0.045 | Train Acc: 98.37%\n",
            "\t Val. Loss: 0.340 |  Val. Acc: 90.06%\n",
            "Epoch: 13 | Epoch Time: 7m 7s\n",
            "\tTrain Loss: 0.046 | Train Acc: 98.24%\n",
            "\t Val. Loss: 0.348 |  Val. Acc: 91.43%\n",
            "Epoch: 14 | Epoch Time: 7m 7s\n",
            "\tTrain Loss: 0.048 | Train Acc: 98.23%\n",
            "\t Val. Loss: 0.337 |  Val. Acc: 92.43%\n",
            "Epoch: 15 | Epoch Time: 7m 6s\n",
            "\tTrain Loss: 0.028 | Train Acc: 99.04%\n",
            "\t Val. Loss: 0.356 |  Val. Acc: 91.06%\n",
            "Epoch: 16 | Epoch Time: 7m 6s\n",
            "\tTrain Loss: 0.031 | Train Acc: 98.86%\n",
            "\t Val. Loss: 0.360 |  Val. Acc: 91.41%\n",
            "Epoch: 17 | Epoch Time: 7m 6s\n",
            "\tTrain Loss: 0.030 | Train Acc: 98.93%\n",
            "\t Val. Loss: 0.408 |  Val. Acc: 91.25%\n",
            "Epoch: 18 | Epoch Time: 7m 7s\n",
            "\tTrain Loss: 0.023 | Train Acc: 99.17%\n",
            "\t Val. Loss: 0.369 |  Val. Acc: 91.19%\n",
            "Epoch: 19 | Epoch Time: 7m 7s\n",
            "\tTrain Loss: 0.026 | Train Acc: 99.10%\n",
            "\t Val. Loss: 0.373 |  Val. Acc: 91.45%\n",
            "Epoch: 20 | Epoch Time: 7m 6s\n",
            "\tTrain Loss: 0.020 | Train Acc: 99.27%\n",
            "\t Val. Loss: 0.468 |  Val. Acc: 90.47%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-3pzP2GRCFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "850c3f10-3034-4eff-d2d9-b17bb464ffc2"
      },
      "source": [
        "#loading the model with minimum valid_loss\n",
        "model.load_state_dict(torch.load('tut6-model.pt'))\n",
        "# testing on our test_data\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.213 | Test Acc: 91.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOI41n1BRCr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_sentiment(model, tokenizer, sentence):\n",
        "    \"\"\" returns the prediction of model on the input sentence using the model\"\"\"\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9ne1ovtRFDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df8c1ee9-0254-4fec-b10e-deb0b3fdc7e6"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"This film is terrible\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015748243778944016"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeoVeUcRRHW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74cd492d-7aef-4b33-b520-42f872663f31"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"This film is great\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.950927734375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN for sentiment analysis of IMDB reviews dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBWlPMfnesHk",
        "colab_type": "text"
      },
      "source": [
        "##RNN for sentiment analysis using IMDB dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7cLpLENgXXl",
        "colab_type": "text"
      },
      "source": [
        "Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj0rOnjMerOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch #importing pytorch\n",
        "from torchtext import data #pytorch library for preprocessing\n",
        "import torch.nn.functional as F\n",
        "#setting random seed\n",
        "SEED = 1234\n",
        "# setting manual seed using our random seed to get the same random number\n",
        "torch.manual_seed(SEED)\n",
        "# running on the CuDNN backend\n",
        "torch.backends.cudnn.deterministic = True\n",
        "# tokenizing text using spacy tokenizer\n",
        "TEXT = data.Field(tokenize = 'spacy')\n",
        "# Labelling our dataset and setting tensor to FloatTensors\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7bEBxs6gLOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import datasets # to get torch dataset\n",
        "# downloading the IMDb dataset and spliting it into the canonical train/test splits as torchtext.datasets objects\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiEAh9QWiFHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d68873d2-7f2d-44b0-812b-ac4a7a519f73"
      },
      "source": [
        "# Checking length of train test splits\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmA32JD5iOub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f8f4a5ca-1154-4f17-d2d9-66292e75027c"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['So', ',', 'neighbor', 'was', 'killing', 'neighbor', '.', 'Reminds', 'me', 'of', 'Iraq', '.', 'As', 'I', 'watched', 'the', 'American', 'flag', '(', '50', 'stars', 'in', '1864', '?', ')', 'being', 'dragged', 'behind', 'the', 'horse', ',', 'I', 'realized', 'why', 'burning', 'that', 'piece', 'of', 'red', 'white', 'and', 'blue', 'does', \"n't\", 'upset', 'me', 'as', 'much', 'as', 'our', 'destruction', '/', 'indifference', 'to', 'the', 'Bill', 'of', 'Rights', '.', 'I', \"'m\", 'a', 'Southerner', ',', 'and', 'must', 'have', 'some', 'historical', 'memory.<br', '/><br', '/>Watching', 'the', 'Tobey', 'McGuire', 'character', 'learn', 'to', 'respect', 'the', 'dignity', 'of', 'a', 'former', 'slave', ',', 'as', 'he', 'looks', 'at', 'the', 'scalps', 'of', 'blacks', 'and', 'Germans', '(', 'his', 'ethnic', 'background', ')', 'being', 'wagered', 'at', 'a', 'poker', 'game', '.....', 'was', 'interesting', '.', 'Many', 'twists', 'in', 'this', 'movie', '.', 'The', 'wife', ',', 'who', 'is', 'forced', 'into', 'her', 'marriage', ',', 'shows', 'both', 'lust', 'and', 'a', 'strong', 'will', ',', 'characteristics', 'we', \"'re\", 'not', 'used', 'to', 'seeing', 'in', \"'\", 'respectable', 'Victorian', 'southern', \"belles'.<br\", '/><br', '/>The', 'crazy', 'wacked', 'out', 'renegade', 'southerner', 'gave', 'me', 'some', 'insight', 'into', 'why', 'my', 'cousin', ',', 'head', 'of', 'the', 'Copeland', 'Horse', '-', 'thieving', 'Gang', ',', 'Inc.', 'in', 'Mississippi', ',', 'was', 'hung', 'about', 'that', 'time', '.', 'Bands', 'of', 'homeless', 'men', 'were', 'roaming', 'the', 'countryside', ',', 'armed', '.', 'Remind', 'you', 'of', 'Iraq', '?', 'And', 'how', 'similar', 'we', 'are', 'underneath', 'the', 'facade', 'of', 'religion', 'and', 'ethnic', 'background', '?', 'And', 'why', 'southerners', 'are', 'STILL', 'fighting', 'that', 'civil', 'war', 'today.<br', '/><br', '/>Too', 'bad', 'we', 'ca', \"n't\", 'use', 'that', 'same', 'knowledge', 'in', 'our', 'handling', 'of', 'the', 'country', 'we', \"'ve\", 'just', 'invaded', 'and', 'are', 'occupying', ',', 'fomenting', 'civil', 'war', 'everywhere', '.', 'That', \"'s\", 'Mesopotamia', ',', 'now', 'called', 'Iraq', ',', 'who', 'happen', 'to', 'have', 'the', 'misfortune', 'to', 'sit', 'on', 'oil', '.', 'The', 'wild', '-', 'eyed', 'killers', 'in', 'Missouri', ',', 'raiding', 'Lawrence', ',', 'Kansas', 'could', 'as', 'easily', 'be', 'the', 'insurgents', 'we', \"'re\", 'fighting', 'now', 'with', 'no', 'success.<br', '/><br', '/>Another', 'anomaly', 'was', 'the', 'father', \"'s\", 'tribute', 'to', 'the', 'Yankees', 'who', 'move', 'into', 'Lawrence', 'and', 'erect', 'a', 'school', '\"', 'even', 'before', 'they', 'erect', 'a', 'church', '.', 'And', 'for', 'that', 'reason', ',', 'they', \"'ll\", 'win', '.', '\"', 'Huh', '?', '?', '?', '?', '?', 'I', 'was', 'taught', 'history', 'in', 'Birmingham', ',', 'Al', 'and', 'we', 'were', 'taught', 'that', 'the', 'North', 'was', 'much', 'more', 'industrial', 'and', 'richer', '.....', 'that', \"'s\", 'why', 'they', 'won', '.', 'Course', ',', 'they', 'also', 'LITERALLY', 'had', 'God', 'on', 'their', 'side', '.', 'As', 'you', 'see', 'here', ',', 'when', 'the', 'freed', 'slave', 'indicates', 'that', 'he', \"'s\", 'cutting', 'out', 'to', 'free', 'his', 'mother', ',', 'sold', 'into', 'slavery', 'in', 'Texas', '.', 'God', ',', 'what', 'a', 'horrible', 'legacy', 'slavery', 'gave', 'us.<br', '/><br', '/>Acting', 'pretty', 'good', ',', 'lots', 'of', 'blood', 'and', 'gore', 'as', 'the', 'warriors', 'ride', 'gleefully', 'into', 'battle', '(', 'but', 'did', \"n't\", 'hear', 'any', 'rebel', 'yells', ',', 'so', 'reminiscent', 'of', 'football', 'games', 'in', 'Alabama', ')', '.', 'You', 'also', 'get', 'a', 'real', 'feeling', 'for', 'how', 'stupid', 'the', 'war', 'was', ',', 'as', 'the', 'bushwackers', 'and', 'jayhawkers', 'gather', 'their', 'forces', 'for', 'another', 'raid', '.', 'They', 'have', 'lost', 'sight', 'of', 'why', 'they', \"'re\", 'fighting', ',', 'and', 'so', 'do', 'we', '.', 'Just', 'more', 'mindless', 'slaughter.<br', '/><br', \"/>You're\", 'also', 'brought', 'up', 'to', 'date', 'with', 'the', 'limbless', 'kids', 'coming', 'home', 'from', 'Iraq', ',', 'as', 'the', 'bushwacker', '(', 'ahh', ',', 'what', 'connotations', ')', 'first', 'has', 'his', 'arm', 'seared', 'shut', ',', 'trying', 'to', 'save', 'it', ',', 'then', 'has', 'it', 'amputated', ',', 'and', 'then', 'dies', '.', 'So', 'much', 'suffering', 'for', 'such', 'a', 'stupid', 'cause.<br', '/><br', '/>The', 'cinematography', 'is', 'fantastic', '.', 'Now', 'I', 'have', 'to', 'get', 'back', 'to', 'the', 'DVD', 'and', 'get', 'the', 'production', 'notes', ',', 'one', 'of', 'my', 'favorite', 'parts', 'of', 'any', 'movie', '.', 'I', 'suspect', 'that', 'this', 'movie', 'was', 'written', 'by', 'a', 'Gore', 'Vidal', ',', 'as', 'the', 'spoken', 'language', 'is', 'of', 'a', 'type', 'you', 'would', 'associate', 'with', 'that', 'era', ',', 'if', 'you', 'knew', 'History', '.', 'The', 'dialogue', 'is', 'definitely', 'thought', '-', 'provoking', '.', 'Not', 'your', 'ordinary', 'blood', 'and', 'guts', 'war', 'movie', ',', 'by', 'any', 'means', '.', 'You', 'see', 'the', 'wounded', 'but', 'still', 'active', '-', 'duty', 'soldiers', ',', 'still', 'fighting', 'cause', 'they', 'have', 'nothing', 'else', 'to', 'do', '.', 'You', 'see', 'the', 'southern', 'raiders', ',', 'living', 'off', 'the', 'land', ',', 'stealing', 'indiscriminately', '.', 'Yet', ',', 'at', 'the', 'beginning', ',', 'you', \"'ve\", 'seen', 'the', 'battle', 'stop', ',', 'so', 'the', 'women', 'could', 'be', 'evacuated', 'from', 'danger', '.', 'As', 'I', 'read', 'the', 'escalating', 'number', 'of', 'women', 'and', 'children', 'dying', 'in', 'Iraq', ',', 'I', \"'m\", 'thinking', ',', '\"', 'Where', 'did', 'we', 'lose', 'our', 'sense', 'of', 'honor', 'as', 'a', 'people', '?', '\"', 'I', 'have', 'forgotten', 'why', 'I', 'sought', 'this', 'movie', 'out', 'and', 'bought', 'it', 'after', '20', 'years', ',', 'but', 'some', 'book', 'somewhere', 'lauded', 'it', '.', 'With', 'good', 'reason', '.', 'Tobey', 'at', 'his', 'best', ',', 'pre', '-', 'Spideyman', '.', 'Buy', 'the', 'DVD', 'or', 'rent', 'it', '.', 'And', 'tell', 'me', 'why', 'others', 'laud', 'this', ',', 'not', 'just', 'liberals', 'cest', 'moi', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWffaWL3iRTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "#creating valdation set and setting random_state so that we get training and validation set same each time\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED),split_ratio=0.8)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id_yap8ZiwWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f355d572-198e-4bf2-82a9-60f86caf8d7e"
      },
      "source": [
        "# Checking length of train,test, validation splits\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPuOWRL9i7iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building the vocabulary, only keeping the most common max_size tokens using our training set\n",
        "MAX_VOCAB_SIZE = 25_000 \n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBB-J4F3jjYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6b4abec6-5b35-4935-9ced-adefd797915a"
      },
      "source": [
        "# Unique tokens in TEXT vocabulary and LABEL vocabulary\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyBqTqgpkSuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "53d83d4b-59ed-446d-dcd5-ccbc252334d6"
      },
      "source": [
        "#to view the most common words in the vocabulary and their frequencies\n",
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 232582), (',', 221092), ('.', 189740), ('and', 125326), ('a', 124882), ('of', 114980), ('to', 107347), ('is', 87551), ('in', 70313), ('I', 62454), ('it', 61401), ('that', 56774), ('\"', 50544), (\"'s\", 49584), ('this', 48507), ('-', 42205), ('/><br', 40788), ('was', 40044), ('as', 34706), ('with', 34223)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFk-vs5tkaIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "167306d2-466a-43c7-8f35-73e171ff2ace"
      },
      "source": [
        "# We can also see the vocabulary directly using either the stoi (string to int) or itos (int to string) method.\n",
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgU55WZxkn02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ce10292-73ab-46fe-a2bc-552d99e5cc6f"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fcda44b1ea0>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOaqYe_7kqQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We then create the iterators. We iterate over these in the training/evaluation loop, and \n",
        "#they return a batch of examples (indexed and converted into tensors) at each iteration.\n",
        "#We'll use a BucketIterator which is a special type of iterator that will return\n",
        "#a batch of examples where each example is of a similar length, minimizing \n",
        "#the amount of padding per example.\n",
        "#We also want to place the tensors returned by the iterator on the \n",
        "#GPU (if you're using one). PyTorch handles this using torch.device, \n",
        "#we then pass this device to the iterator.\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Gk4EtKlKg-",
        "colab_type": "text"
      },
      "source": [
        "Building our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXHY5PyFlIAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn # neural network library of pytorch\n",
        "# Defining our RNN class as a sub-class of nn.Module \n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \"\"\" this function takes input layer, embedding layer , hidden layer and output layer dimensions and creates layers of our NN\"\"\"\n",
        "        #inheriting init function of nn.Module class \n",
        "        super().__init__()\n",
        "        # embedding layer with input of input_dim and output of embedding_dim\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        # hidden RNN layer with input of embedding_dim and output of hidden_dim\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
        "        # ouput layer with input of input_dim and output of output_dim\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        # input batch passed through the embedding layer to get embedded\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        #feeding embedding into RNN\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "        # verifying that hidden is simply the final hidden state where squeeze method is used to remove a dimension of size 1.\n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        #feeding the last hidden state, hidden, through the linear layer, fc, to produce a prediction\n",
        "        return self.fc(hidden.squeeze(0)).view(-1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LUNbQUWnxGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to create an instance of our RNN class by passing INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM and OUTPUT_DIM\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTD5-cWOoBBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "05f9251e-ec0a-4fc4-c420-3f43b1d83a5a"
      },
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"tell us how many trainable parameters our model has so we can compare the number of parameters across different models\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,592,105 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au9l-qJuoNCA",
        "colab_type": "text"
      },
      "source": [
        "Training our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iirzXMOeoLWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim #optimizer\n",
        "# we use ADAM with learning rate as 0.0001\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAO5VS0hoiFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BCEWithLogitsLoss criterion carries out both the sigmoid(since output of our RNN model is unbounded real number) and the binary cross entropy steps.\n",
        "#criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFGu_0Gko8iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#putting model and criterion to our device\n",
        "model = model.to(device)\n",
        "#criterion = criterion.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4xUsPWFpGd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_binary_accuracy(model, data_loader, device):\n",
        "    \"\"\" returns accuracy per batch i.e percentage of correct predictions to total number of examples\"\"\"\n",
        "    model.eval()\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    #turning off calculation of gradient\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch_data in enumerate(data_loader):\n",
        "            logits = model(batch_data.text)\n",
        "            predicted_labels = (torch.sigmoid(logits) > 0.5).long()\n",
        "            num_examples += batch_data.label.size(0)\n",
        "            correct_pred += (predicted_labels == batch_data.label.long()).sum()\n",
        "        return correct_pred.float()/num_examples * 100"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGZYuWns0AMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca00d1fa-2b3c-4dff-8245-420585cadad0"
      },
      "source": [
        "import time \n",
        "start_time = time.time()\n",
        "NUM_EPOCHS=15\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for batch_idx, batch_data in enumerate(train_iterator):\n",
        "        \n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits = model(batch_data.text)\n",
        "        cost = F.binary_cross_entropy_with_logits(logits, batch_data.label)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx:03d}/{len(train_iterator):03d} | '\n",
        "                   f'Cost: {cost:.4f}')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'training accuracy: '\n",
        "              f'{compute_binary_accuracy(model, train_iterator, device):.2f}%'\n",
        "              f'\\nvalid accuracy: '\n",
        "              f'{compute_binary_accuracy(model, valid_iterator, device):.2f}%')\n",
        "        \n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "    \n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "print(f'Test accuracy: {compute_binary_accuracy(model, test_iterator, device):.2f}%')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/015 | Batch 000/313 | Cost: 0.7252\n",
            "Epoch: 001/015 | Batch 050/313 | Cost: 0.6887\n",
            "Epoch: 001/015 | Batch 100/313 | Cost: 0.6962\n",
            "Epoch: 001/015 | Batch 150/313 | Cost: 0.6910\n",
            "Epoch: 001/015 | Batch 200/313 | Cost: 0.6946\n",
            "Epoch: 001/015 | Batch 250/313 | Cost: 0.6927\n",
            "Epoch: 001/015 | Batch 300/313 | Cost: 0.6927\n",
            "training accuracy: 50.40%\n",
            "valid accuracy: 49.90%\n",
            "Time elapsed: 1.20 min\n",
            "Epoch: 002/015 | Batch 000/313 | Cost: 0.6943\n",
            "Epoch: 002/015 | Batch 050/313 | Cost: 0.6938\n",
            "Epoch: 002/015 | Batch 100/313 | Cost: 0.6954\n",
            "Epoch: 002/015 | Batch 150/313 | Cost: 0.7206\n",
            "Epoch: 002/015 | Batch 200/313 | Cost: 0.6983\n",
            "Epoch: 002/015 | Batch 250/313 | Cost: 0.6941\n",
            "Epoch: 002/015 | Batch 300/313 | Cost: 0.6876\n",
            "training accuracy: 50.37%\n",
            "valid accuracy: 49.94%\n",
            "Time elapsed: 2.39 min\n",
            "Epoch: 003/015 | Batch 000/313 | Cost: 0.6914\n",
            "Epoch: 003/015 | Batch 050/313 | Cost: 0.6916\n",
            "Epoch: 003/015 | Batch 100/313 | Cost: 0.7147\n",
            "Epoch: 003/015 | Batch 150/313 | Cost: 0.6923\n",
            "Epoch: 003/015 | Batch 200/313 | Cost: 0.7065\n",
            "Epoch: 003/015 | Batch 250/313 | Cost: 0.6936\n",
            "Epoch: 003/015 | Batch 300/313 | Cost: 0.6788\n",
            "training accuracy: 49.93%\n",
            "valid accuracy: 51.36%\n",
            "Time elapsed: 3.59 min\n",
            "Epoch: 004/015 | Batch 000/313 | Cost: 0.6898\n",
            "Epoch: 004/015 | Batch 050/313 | Cost: 0.7004\n",
            "Epoch: 004/015 | Batch 100/313 | Cost: 0.6927\n",
            "Epoch: 004/015 | Batch 150/313 | Cost: 0.6916\n",
            "Epoch: 004/015 | Batch 200/313 | Cost: 0.6954\n",
            "Epoch: 004/015 | Batch 250/313 | Cost: 0.6926\n",
            "Epoch: 004/015 | Batch 300/313 | Cost: 0.6882\n",
            "training accuracy: 50.49%\n",
            "valid accuracy: 50.36%\n",
            "Time elapsed: 4.78 min\n",
            "Epoch: 005/015 | Batch 000/313 | Cost: 0.6973\n",
            "Epoch: 005/015 | Batch 050/313 | Cost: 0.7014\n",
            "Epoch: 005/015 | Batch 100/313 | Cost: 0.6901\n",
            "Epoch: 005/015 | Batch 150/313 | Cost: 0.6874\n",
            "Epoch: 005/015 | Batch 200/313 | Cost: 0.6909\n",
            "Epoch: 005/015 | Batch 250/313 | Cost: 0.6931\n",
            "Epoch: 005/015 | Batch 300/313 | Cost: 0.6899\n",
            "training accuracy: 50.54%\n",
            "valid accuracy: 50.10%\n",
            "Time elapsed: 5.98 min\n",
            "Epoch: 006/015 | Batch 000/313 | Cost: 0.7130\n",
            "Epoch: 006/015 | Batch 050/313 | Cost: 0.6929\n",
            "Epoch: 006/015 | Batch 100/313 | Cost: 0.6994\n",
            "Epoch: 006/015 | Batch 150/313 | Cost: 0.6882\n",
            "Epoch: 006/015 | Batch 200/313 | Cost: 0.7029\n",
            "Epoch: 006/015 | Batch 250/313 | Cost: 0.6930\n",
            "Epoch: 006/015 | Batch 300/313 | Cost: 0.6941\n",
            "training accuracy: 50.18%\n",
            "valid accuracy: 51.08%\n",
            "Time elapsed: 7.18 min\n",
            "Epoch: 007/015 | Batch 000/313 | Cost: 0.6880\n",
            "Epoch: 007/015 | Batch 050/313 | Cost: 0.6898\n",
            "Epoch: 007/015 | Batch 100/313 | Cost: 0.6939\n",
            "Epoch: 007/015 | Batch 150/313 | Cost: 0.6968\n",
            "Epoch: 007/015 | Batch 200/313 | Cost: 0.6924\n",
            "Epoch: 007/015 | Batch 250/313 | Cost: 0.6873\n",
            "Epoch: 007/015 | Batch 300/313 | Cost: 0.6941\n",
            "training accuracy: 50.14%\n",
            "valid accuracy: 50.74%\n",
            "Time elapsed: 8.38 min\n",
            "Epoch: 008/015 | Batch 000/313 | Cost: 0.6946\n",
            "Epoch: 008/015 | Batch 050/313 | Cost: 0.6860\n",
            "Epoch: 008/015 | Batch 100/313 | Cost: 0.6850\n",
            "Epoch: 008/015 | Batch 150/313 | Cost: 0.7015\n",
            "Epoch: 008/015 | Batch 200/313 | Cost: 0.6972\n",
            "Epoch: 008/015 | Batch 250/313 | Cost: 0.6836\n",
            "Epoch: 008/015 | Batch 300/313 | Cost: 0.7028\n",
            "training accuracy: 50.64%\n",
            "valid accuracy: 49.84%\n",
            "Time elapsed: 9.58 min\n",
            "Epoch: 009/015 | Batch 000/313 | Cost: 0.6966\n",
            "Epoch: 009/015 | Batch 050/313 | Cost: 0.7040\n",
            "Epoch: 009/015 | Batch 100/313 | Cost: 0.6852\n",
            "Epoch: 009/015 | Batch 150/313 | Cost: 0.6944\n",
            "Epoch: 009/015 | Batch 200/313 | Cost: 0.6923\n",
            "Epoch: 009/015 | Batch 250/313 | Cost: 0.6809\n",
            "Epoch: 009/015 | Batch 300/313 | Cost: 0.6890\n",
            "training accuracy: 50.18%\n",
            "valid accuracy: 50.94%\n",
            "Time elapsed: 10.78 min\n",
            "Epoch: 010/015 | Batch 000/313 | Cost: 0.6891\n",
            "Epoch: 010/015 | Batch 050/313 | Cost: 0.6948\n",
            "Epoch: 010/015 | Batch 100/313 | Cost: 0.6838\n",
            "Epoch: 010/015 | Batch 150/313 | Cost: 0.6920\n",
            "Epoch: 010/015 | Batch 200/313 | Cost: 0.6771\n",
            "Epoch: 010/015 | Batch 250/313 | Cost: 0.6924\n",
            "Epoch: 010/015 | Batch 300/313 | Cost: 0.7021\n",
            "training accuracy: 50.23%\n",
            "valid accuracy: 50.90%\n",
            "Time elapsed: 11.98 min\n",
            "Epoch: 011/015 | Batch 000/313 | Cost: 0.6965\n",
            "Epoch: 011/015 | Batch 050/313 | Cost: 0.6871\n",
            "Epoch: 011/015 | Batch 100/313 | Cost: 0.6829\n",
            "Epoch: 011/015 | Batch 150/313 | Cost: 0.6834\n",
            "Epoch: 011/015 | Batch 200/313 | Cost: 0.6958\n",
            "Epoch: 011/015 | Batch 250/313 | Cost: 0.6950\n",
            "Epoch: 011/015 | Batch 300/313 | Cost: 0.6936\n",
            "training accuracy: 50.15%\n",
            "valid accuracy: 50.80%\n",
            "Time elapsed: 13.18 min\n",
            "Epoch: 012/015 | Batch 000/313 | Cost: 0.6878\n",
            "Epoch: 012/015 | Batch 050/313 | Cost: 0.6888\n",
            "Epoch: 012/015 | Batch 100/313 | Cost: 0.6891\n",
            "Epoch: 012/015 | Batch 150/313 | Cost: 0.6837\n",
            "Epoch: 012/015 | Batch 200/313 | Cost: 0.6873\n",
            "Epoch: 012/015 | Batch 250/313 | Cost: 0.7037\n",
            "Epoch: 012/015 | Batch 300/313 | Cost: 0.6895\n",
            "training accuracy: 50.13%\n",
            "valid accuracy: 50.36%\n",
            "Time elapsed: 14.38 min\n",
            "Epoch: 013/015 | Batch 000/313 | Cost: 0.7007\n",
            "Epoch: 013/015 | Batch 050/313 | Cost: 0.6877\n",
            "Epoch: 013/015 | Batch 100/313 | Cost: 0.6965\n",
            "Epoch: 013/015 | Batch 150/313 | Cost: 0.6952\n",
            "Epoch: 013/015 | Batch 200/313 | Cost: 0.6899\n",
            "Epoch: 013/015 | Batch 250/313 | Cost: 0.6909\n",
            "Epoch: 013/015 | Batch 300/313 | Cost: 0.6862\n",
            "training accuracy: 50.65%\n",
            "valid accuracy: 50.02%\n",
            "Time elapsed: 15.58 min\n",
            "Epoch: 014/015 | Batch 000/313 | Cost: 0.6847\n",
            "Epoch: 014/015 | Batch 050/313 | Cost: 0.6921\n",
            "Epoch: 014/015 | Batch 100/313 | Cost: 0.6834\n",
            "Epoch: 014/015 | Batch 150/313 | Cost: 0.6951\n",
            "Epoch: 014/015 | Batch 200/313 | Cost: 0.6920\n",
            "Epoch: 014/015 | Batch 250/313 | Cost: 0.6885\n",
            "Epoch: 014/015 | Batch 300/313 | Cost: 0.6853\n",
            "training accuracy: 50.70%\n",
            "valid accuracy: 49.80%\n",
            "Time elapsed: 16.78 min\n",
            "Epoch: 015/015 | Batch 000/313 | Cost: 0.6865\n",
            "Epoch: 015/015 | Batch 050/313 | Cost: 0.6933\n",
            "Epoch: 015/015 | Batch 100/313 | Cost: 0.6919\n",
            "Epoch: 015/015 | Batch 150/313 | Cost: 0.6831\n",
            "Epoch: 015/015 | Batch 200/313 | Cost: 0.6845\n",
            "Epoch: 015/015 | Batch 250/313 | Cost: 0.6843\n",
            "Epoch: 015/015 | Batch 300/313 | Cost: 0.6872\n",
            "training accuracy: 50.27%\n",
            "valid accuracy: 50.16%\n",
            "Time elapsed: 17.97 min\n",
            "Total Training Time: 17.97 min\n",
            "Test accuracy: 48.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoIMCsSQvva4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy \n",
        "nlp = spacy.load('en')\n",
        "def predict_sentiment(model, sentence):\n",
        "    \"\"\" inputs the sentence and the model and outputs the sentiment of sentence based on the model\"\"\"\n",
        "    model.eval()\n",
        "    tokenized = [token.text for token in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    if (prediction.item())>=0.5:\n",
        "        return \"Positive with score \"+ str(prediction.item())\n",
        "    else:\n",
        "        return \"Negative with score \"+ str(prediction.item())\n",
        "        "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4hLReu0wxL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cfed12b2-44f8-4f8c-c909-a31ae03bc864"
      },
      "source": [
        "predict_sentiment(model, \"I really love this movie.This movie is so great!\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive with score 0.5495536923408508'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}
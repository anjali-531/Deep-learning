{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM for sentiment analysis of IMDB reviews dataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBWlPMfnesHk",
        "colab_type": "text"
      },
      "source": [
        "##LSTM for sentiment analysis using IMDB dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7cLpLENgXXl",
        "colab_type": "text"
      },
      "source": [
        "Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj0rOnjMerOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch #importing pytorch\n",
        "from torchtext import data #pytorch library for preprocessing\n",
        "import torch.nn.functional as F\n",
        "#setting random seed\n",
        "SEED = 1234\n",
        "# setting manual seed using our random seed to get the same random number\n",
        "torch.manual_seed(SEED)\n",
        "# running on the CuDNN backend\n",
        "torch.backends.cudnn.deterministic = True\n",
        "# tokenizing text using spacy tokenizer and include lengths for packed padded sequences\n",
        "TEXT = data.Field(tokenize = 'spacy',include_lengths=True) \n",
        "# Labelling our dataset and setting tensor to FloatTensors\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7bEBxs6gLOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import datasets # to get torch dataset\n",
        "# downloading the IMDb dataset and spliting it into the canonical train/test splits as torchtext.datasets objects\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiEAh9QWiFHR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ee2b8a14-a1d7-4481-885a-302bb4aa4fe2"
      },
      "source": [
        "# Checking length of train test splits\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmA32JD5iOub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "335722b6-1974-4cfa-96d6-2c69196ce7bd"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['So', ',', 'neighbor', 'was', 'killing', 'neighbor', '.', 'Reminds', 'me', 'of', 'Iraq', '.', 'As', 'I', 'watched', 'the', 'American', 'flag', '(', '50', 'stars', 'in', '1864', '?', ')', 'being', 'dragged', 'behind', 'the', 'horse', ',', 'I', 'realized', 'why', 'burning', 'that', 'piece', 'of', 'red', 'white', 'and', 'blue', 'does', \"n't\", 'upset', 'me', 'as', 'much', 'as', 'our', 'destruction', '/', 'indifference', 'to', 'the', 'Bill', 'of', 'Rights', '.', 'I', \"'m\", 'a', 'Southerner', ',', 'and', 'must', 'have', 'some', 'historical', 'memory.<br', '/><br', '/>Watching', 'the', 'Tobey', 'McGuire', 'character', 'learn', 'to', 'respect', 'the', 'dignity', 'of', 'a', 'former', 'slave', ',', 'as', 'he', 'looks', 'at', 'the', 'scalps', 'of', 'blacks', 'and', 'Germans', '(', 'his', 'ethnic', 'background', ')', 'being', 'wagered', 'at', 'a', 'poker', 'game', '.....', 'was', 'interesting', '.', 'Many', 'twists', 'in', 'this', 'movie', '.', 'The', 'wife', ',', 'who', 'is', 'forced', 'into', 'her', 'marriage', ',', 'shows', 'both', 'lust', 'and', 'a', 'strong', 'will', ',', 'characteristics', 'we', \"'re\", 'not', 'used', 'to', 'seeing', 'in', \"'\", 'respectable', 'Victorian', 'southern', \"belles'.<br\", '/><br', '/>The', 'crazy', 'wacked', 'out', 'renegade', 'southerner', 'gave', 'me', 'some', 'insight', 'into', 'why', 'my', 'cousin', ',', 'head', 'of', 'the', 'Copeland', 'Horse', '-', 'thieving', 'Gang', ',', 'Inc.', 'in', 'Mississippi', ',', 'was', 'hung', 'about', 'that', 'time', '.', 'Bands', 'of', 'homeless', 'men', 'were', 'roaming', 'the', 'countryside', ',', 'armed', '.', 'Remind', 'you', 'of', 'Iraq', '?', 'And', 'how', 'similar', 'we', 'are', 'underneath', 'the', 'facade', 'of', 'religion', 'and', 'ethnic', 'background', '?', 'And', 'why', 'southerners', 'are', 'STILL', 'fighting', 'that', 'civil', 'war', 'today.<br', '/><br', '/>Too', 'bad', 'we', 'ca', \"n't\", 'use', 'that', 'same', 'knowledge', 'in', 'our', 'handling', 'of', 'the', 'country', 'we', \"'ve\", 'just', 'invaded', 'and', 'are', 'occupying', ',', 'fomenting', 'civil', 'war', 'everywhere', '.', 'That', \"'s\", 'Mesopotamia', ',', 'now', 'called', 'Iraq', ',', 'who', 'happen', 'to', 'have', 'the', 'misfortune', 'to', 'sit', 'on', 'oil', '.', 'The', 'wild', '-', 'eyed', 'killers', 'in', 'Missouri', ',', 'raiding', 'Lawrence', ',', 'Kansas', 'could', 'as', 'easily', 'be', 'the', 'insurgents', 'we', \"'re\", 'fighting', 'now', 'with', 'no', 'success.<br', '/><br', '/>Another', 'anomaly', 'was', 'the', 'father', \"'s\", 'tribute', 'to', 'the', 'Yankees', 'who', 'move', 'into', 'Lawrence', 'and', 'erect', 'a', 'school', '\"', 'even', 'before', 'they', 'erect', 'a', 'church', '.', 'And', 'for', 'that', 'reason', ',', 'they', \"'ll\", 'win', '.', '\"', 'Huh', '?', '?', '?', '?', '?', 'I', 'was', 'taught', 'history', 'in', 'Birmingham', ',', 'Al', 'and', 'we', 'were', 'taught', 'that', 'the', 'North', 'was', 'much', 'more', 'industrial', 'and', 'richer', '.....', 'that', \"'s\", 'why', 'they', 'won', '.', 'Course', ',', 'they', 'also', 'LITERALLY', 'had', 'God', 'on', 'their', 'side', '.', 'As', 'you', 'see', 'here', ',', 'when', 'the', 'freed', 'slave', 'indicates', 'that', 'he', \"'s\", 'cutting', 'out', 'to', 'free', 'his', 'mother', ',', 'sold', 'into', 'slavery', 'in', 'Texas', '.', 'God', ',', 'what', 'a', 'horrible', 'legacy', 'slavery', 'gave', 'us.<br', '/><br', '/>Acting', 'pretty', 'good', ',', 'lots', 'of', 'blood', 'and', 'gore', 'as', 'the', 'warriors', 'ride', 'gleefully', 'into', 'battle', '(', 'but', 'did', \"n't\", 'hear', 'any', 'rebel', 'yells', ',', 'so', 'reminiscent', 'of', 'football', 'games', 'in', 'Alabama', ')', '.', 'You', 'also', 'get', 'a', 'real', 'feeling', 'for', 'how', 'stupid', 'the', 'war', 'was', ',', 'as', 'the', 'bushwackers', 'and', 'jayhawkers', 'gather', 'their', 'forces', 'for', 'another', 'raid', '.', 'They', 'have', 'lost', 'sight', 'of', 'why', 'they', \"'re\", 'fighting', ',', 'and', 'so', 'do', 'we', '.', 'Just', 'more', 'mindless', 'slaughter.<br', '/><br', \"/>You're\", 'also', 'brought', 'up', 'to', 'date', 'with', 'the', 'limbless', 'kids', 'coming', 'home', 'from', 'Iraq', ',', 'as', 'the', 'bushwacker', '(', 'ahh', ',', 'what', 'connotations', ')', 'first', 'has', 'his', 'arm', 'seared', 'shut', ',', 'trying', 'to', 'save', 'it', ',', 'then', 'has', 'it', 'amputated', ',', 'and', 'then', 'dies', '.', 'So', 'much', 'suffering', 'for', 'such', 'a', 'stupid', 'cause.<br', '/><br', '/>The', 'cinematography', 'is', 'fantastic', '.', 'Now', 'I', 'have', 'to', 'get', 'back', 'to', 'the', 'DVD', 'and', 'get', 'the', 'production', 'notes', ',', 'one', 'of', 'my', 'favorite', 'parts', 'of', 'any', 'movie', '.', 'I', 'suspect', 'that', 'this', 'movie', 'was', 'written', 'by', 'a', 'Gore', 'Vidal', ',', 'as', 'the', 'spoken', 'language', 'is', 'of', 'a', 'type', 'you', 'would', 'associate', 'with', 'that', 'era', ',', 'if', 'you', 'knew', 'History', '.', 'The', 'dialogue', 'is', 'definitely', 'thought', '-', 'provoking', '.', 'Not', 'your', 'ordinary', 'blood', 'and', 'guts', 'war', 'movie', ',', 'by', 'any', 'means', '.', 'You', 'see', 'the', 'wounded', 'but', 'still', 'active', '-', 'duty', 'soldiers', ',', 'still', 'fighting', 'cause', 'they', 'have', 'nothing', 'else', 'to', 'do', '.', 'You', 'see', 'the', 'southern', 'raiders', ',', 'living', 'off', 'the', 'land', ',', 'stealing', 'indiscriminately', '.', 'Yet', ',', 'at', 'the', 'beginning', ',', 'you', \"'ve\", 'seen', 'the', 'battle', 'stop', ',', 'so', 'the', 'women', 'could', 'be', 'evacuated', 'from', 'danger', '.', 'As', 'I', 'read', 'the', 'escalating', 'number', 'of', 'women', 'and', 'children', 'dying', 'in', 'Iraq', ',', 'I', \"'m\", 'thinking', ',', '\"', 'Where', 'did', 'we', 'lose', 'our', 'sense', 'of', 'honor', 'as', 'a', 'people', '?', '\"', 'I', 'have', 'forgotten', 'why', 'I', 'sought', 'this', 'movie', 'out', 'and', 'bought', 'it', 'after', '20', 'years', ',', 'but', 'some', 'book', 'somewhere', 'lauded', 'it', '.', 'With', 'good', 'reason', '.', 'Tobey', 'at', 'his', 'best', ',', 'pre', '-', 'Spideyman', '.', 'Buy', 'the', 'DVD', 'or', 'rent', 'it', '.', 'And', 'tell', 'me', 'why', 'others', 'laud', 'this', ',', 'not', 'just', 'liberals', 'cest', 'moi', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWffaWL3iRTK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "#creating valdation set and setting random_state so that we get training and validation set same each time\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED),split_ratio=0.8)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id_yap8ZiwWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "52e8f200-8de2-4097-ef46-1566cad902bc"
      },
      "source": [
        "# Checking length of train,test, validation splits\n",
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 20000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPuOWRL9i7iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building the vocabulary, only keeping the most common max_size tokens using our training set\n",
        "MAX_VOCAB_SIZE = 25_000 \n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBB-J4F3jjYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "276c3da4-737f-4821-d734-50f7452b6c84"
      },
      "source": [
        "# Unique tokens in TEXT vocabulary and LABEL vocabulary\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyBqTqgpkSuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "38712e03-afb0-4c04-e4dd-69b08236d8e0"
      },
      "source": [
        "#to view the most common words in the vocabulary and their frequencies\n",
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 232582), (',', 221092), ('.', 189740), ('and', 125326), ('a', 124882), ('of', 114980), ('to', 107347), ('is', 87551), ('in', 70313), ('I', 62454), ('it', 61401), ('that', 56774), ('\"', 50544), (\"'s\", 49584), ('this', 48507), ('-', 42205), ('/><br', 40788), ('was', 40044), ('as', 34706), ('with', 34223)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFk-vs5tkaIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e867312-ed1c-4d49-da61-35c18658a68e"
      },
      "source": [
        "# We can also see the vocabulary directly using either the stoi (string to int) or itos (int to string) method.\n",
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgU55WZxkn02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "510f4c23-8e11-4bef-9ba7-80eb99695c19"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f739579dea0>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOaqYe_7kqQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We then create the iterators. We iterate over these in the training/evaluation loop, and \n",
        "#they return a batch of examples (indexed and converted into tensors) at each iteration.\n",
        "#We'll use a BucketIterator which is a special type of iterator that will return\n",
        "#a batch of examples where each example is of a similar length, minimizing \n",
        "#the amount of padding per example.\n",
        "#We also want to place the tensors returned by the iterator on the \n",
        "#GPU (if you're using one). PyTorch handles this using torch.device, \n",
        "#we then pass this device to the iterator.\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,sort_within_batch=True, #for packed_padded_sequences\n",
        "    device = device)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymh4eoUArlkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "cdacde55-6b13-4f5a-9412-30f39718a9cd"
      },
      "source": [
        "#testing the iterators \n",
        "#number of rows depends on the longest document in the respective batch\n",
        "print('Train')\n",
        "for batch in train_iterator:\n",
        "    print(f'Text matrix size: {batch.text[0].size()}')\n",
        "    print(f'Target vector size: {batch.label.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nValid:')\n",
        "for batch in valid_iterator:\n",
        "    print(f'Text matrix size: {batch.text[0].size()}')\n",
        "    print(f'Target vector size: {batch.label.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nTest:')\n",
        "for batch in test_iterator:\n",
        "    print(f'Text matrix size: {batch.text[0].size()}')\n",
        "    print(f'Target vector size: {batch.label.size()}')\n",
        "    break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "Text matrix size: torch.Size([511, 64])\n",
            "Target vector size: torch.Size([64])\n",
            "\n",
            "Valid:\n",
            "Text matrix size: torch.Size([53, 64])\n",
            "Target vector size: torch.Size([64])\n",
            "\n",
            "Test:\n",
            "Text matrix size: torch.Size([36, 64])\n",
            "Target vector size: torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8Gk4EtKlKg-",
        "colab_type": "text"
      },
      "source": [
        "Building our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXHY5PyFlIAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn # neural network library of pytorch\n",
        "# Defining our RNN class as a sub-class of nn.Module \n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \"\"\" this function takes input layer, embedding layer , hidden layer and output layer dimensions and creates layers of our NN\"\"\"\n",
        "        #inheriting init function of nn.Module class \n",
        "        super().__init__()\n",
        "        # embedding layer with input of input_dim and output of embedding_dim\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        # hidden LSTM layer with input of embedding_dim and output of hidden_dim\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        # ouput layer with input of input_dim and output of output_dim\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text,text_length):\n",
        "\n",
        "        #[sentence len, batch size] => [sentence len, batch size, embedding size]\n",
        "        # input batch passed through the embedding layer to get embedded\n",
        "        embedded = self.embedding(text)\n",
        "        # to pack a text tensor containing padded sequences of variable length.\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, text_length)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        #feeding embedding into RNN\n",
        "        packed_output, (hidden, cell) = self.rnn(packed)\n",
        "        \n",
        "        #[sentence len, batch size, embedding size] => \n",
        "        #  output: [sentence len, batch size, hidden size]\n",
        "        #  hidden: [1, batch size, hidden size]\n",
        "        #feeding the last hidden state, hidden, through the linear layer, fc, to produce a prediction\n",
        "        return self.fc(hidden.squeeze(0)).view(-1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LUNbQUWnxGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to create an instance of our RNN class by passing INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM and OUTPUT_DIM\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTD5-cWOoBBS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16fdcde1-f8c0-4956-f01e-9997c5ba9b86"
      },
      "source": [
        "def count_parameters(model):\n",
        "    \"\"\"tell us how many trainable parameters our model has so we can compare the number of parameters across different models\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,867,049 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au9l-qJuoNCA",
        "colab_type": "text"
      },
      "source": [
        "Training our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iirzXMOeoLWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch.optim as optim #optimizer\n",
        "# we use ADAM with learning rate as 0.0001\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFGu_0Gko8iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#putting model and criterion to our device\n",
        "model = model.to(device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4xUsPWFpGd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "def compute_accuracy_and_confusion_matrix(model, data_loader, device,test):\n",
        "    \"\"\" returns accuracy per batch i.e percentage of correct predictions to total number of examples\"\"\"\n",
        "    model.eval()\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    y_predicted=[]\n",
        "    y_true=[]\n",
        "    #turning off calculation of gradient\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch_data in enumerate(data_loader):\n",
        "            text, text_lengths = batch_data.text\n",
        "            logits = model(text, text_lengths)\n",
        "            predicted_labels = (torch.sigmoid(logits) > 0.5).long()\n",
        "            size = [int(x) for x in batch_data.label.long().shape]\n",
        "            for i in range(0,size[0]):\n",
        "                y_predicted.append(predicted_labels[i].item())\n",
        "                y_true.append((batch_data.label.long())[i].item())\n",
        "            num_examples += batch_data.label.size(0)\n",
        "            correct_pred += (predicted_labels == batch_data.label.long()).sum()\n",
        "        if test:\n",
        "            print(\"Confusion Matrix\")\n",
        "            print(metrics.confusion_matrix(y_true, y_predicted,labels=[0,1]))    \n",
        "        return correct_pred.float()/num_examples * 100"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGZYuWns0AMK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d2d6eb75-f700-46c4-ec7d-75937ed302fa"
      },
      "source": [
        "import time \n",
        "start_time = time.time()\n",
        "NUM_EPOCHS=15\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for batch_idx, batch_data in enumerate(train_iterator):\n",
        "        text,text_lengths = batch_data.text\n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits = model(text,text_lengths)\n",
        "        cost = F.binary_cross_entropy_with_logits(logits, batch_data.label)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        cost.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx:03d}/{len(train_iterator):03d} | '\n",
        "                   f'Cost: {cost:.4f}')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'training accuracy: '\n",
        "              f'{compute_accuracy_and_confusion_matrix(model, train_iterator, device,test=False):.2f}%'\n",
        "              f'\\nvalid accuracy: '\n",
        "              f'{compute_accuracy_and_confusion_matrix(model, valid_iterator, device,test=False):.2f}%')\n",
        "        \n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/015 | Batch 000/313 | Cost: 0.0016\n",
            "Epoch: 001/015 | Batch 050/313 | Cost: 0.0039\n",
            "Epoch: 001/015 | Batch 100/313 | Cost: 0.0599\n",
            "Epoch: 001/015 | Batch 150/313 | Cost: 0.2715\n",
            "Epoch: 001/015 | Batch 200/313 | Cost: 0.0066\n",
            "Epoch: 001/015 | Batch 250/313 | Cost: 0.0054\n",
            "Epoch: 001/015 | Batch 300/313 | Cost: 0.0899\n",
            "training accuracy: 99.88%\n",
            "valid accuracy: 85.72%\n",
            "Time elapsed: 0.25 min\n",
            "Epoch: 002/015 | Batch 000/313 | Cost: 0.0164\n",
            "Epoch: 002/015 | Batch 050/313 | Cost: 0.0012\n",
            "Epoch: 002/015 | Batch 100/313 | Cost: 0.0039\n",
            "Epoch: 002/015 | Batch 150/313 | Cost: 0.0011\n",
            "Epoch: 002/015 | Batch 200/313 | Cost: 0.0027\n",
            "Epoch: 002/015 | Batch 250/313 | Cost: 0.0018\n",
            "Epoch: 002/015 | Batch 300/313 | Cost: 0.0059\n",
            "training accuracy: 99.92%\n",
            "valid accuracy: 85.74%\n",
            "Time elapsed: 0.50 min\n",
            "Epoch: 003/015 | Batch 000/313 | Cost: 0.0037\n",
            "Epoch: 003/015 | Batch 050/313 | Cost: 0.0020\n",
            "Epoch: 003/015 | Batch 100/313 | Cost: 0.0018\n",
            "Epoch: 003/015 | Batch 150/313 | Cost: 0.0035\n",
            "Epoch: 003/015 | Batch 200/313 | Cost: 0.0004\n",
            "Epoch: 003/015 | Batch 250/313 | Cost: 0.0436\n",
            "Epoch: 003/015 | Batch 300/313 | Cost: 0.0139\n",
            "training accuracy: 99.46%\n",
            "valid accuracy: 85.46%\n",
            "Time elapsed: 0.75 min\n",
            "Epoch: 004/015 | Batch 000/313 | Cost: 0.0015\n",
            "Epoch: 004/015 | Batch 050/313 | Cost: 0.0037\n",
            "Epoch: 004/015 | Batch 100/313 | Cost: 0.0089\n",
            "Epoch: 004/015 | Batch 150/313 | Cost: 0.0174\n",
            "Epoch: 004/015 | Batch 200/313 | Cost: 0.0059\n",
            "Epoch: 004/015 | Batch 250/313 | Cost: 0.0099\n",
            "Epoch: 004/015 | Batch 300/313 | Cost: 0.2638\n",
            "training accuracy: 76.28%\n",
            "valid accuracy: 68.40%\n",
            "Time elapsed: 1.00 min\n",
            "Epoch: 005/015 | Batch 000/313 | Cost: 0.6304\n",
            "Epoch: 005/015 | Batch 050/313 | Cost: 0.6243\n",
            "Epoch: 005/015 | Batch 100/313 | Cost: 0.1989\n",
            "Epoch: 005/015 | Batch 150/313 | Cost: 0.0424\n",
            "Epoch: 005/015 | Batch 200/313 | Cost: 0.0115\n",
            "Epoch: 005/015 | Batch 250/313 | Cost: 0.0061\n",
            "Epoch: 005/015 | Batch 300/313 | Cost: 0.0251\n",
            "training accuracy: 97.88%\n",
            "valid accuracy: 84.26%\n",
            "Time elapsed: 1.25 min\n",
            "Epoch: 006/015 | Batch 000/313 | Cost: 0.0764\n",
            "Epoch: 006/015 | Batch 050/313 | Cost: 0.0078\n",
            "Epoch: 006/015 | Batch 100/313 | Cost: 0.0079\n",
            "Epoch: 006/015 | Batch 150/313 | Cost: 0.0188\n",
            "Epoch: 006/015 | Batch 200/313 | Cost: 0.0064\n",
            "Epoch: 006/015 | Batch 250/313 | Cost: 0.0152\n",
            "Epoch: 006/015 | Batch 300/313 | Cost: 0.0115\n",
            "training accuracy: 99.83%\n",
            "valid accuracy: 85.90%\n",
            "Time elapsed: 1.50 min\n",
            "Epoch: 007/015 | Batch 000/313 | Cost: 0.0062\n",
            "Epoch: 007/015 | Batch 050/313 | Cost: 0.0087\n",
            "Epoch: 007/015 | Batch 100/313 | Cost: 0.0027\n",
            "Epoch: 007/015 | Batch 150/313 | Cost: 0.0058\n",
            "Epoch: 007/015 | Batch 200/313 | Cost: 0.0055\n",
            "Epoch: 007/015 | Batch 250/313 | Cost: 0.0040\n",
            "Epoch: 007/015 | Batch 300/313 | Cost: 0.0175\n",
            "training accuracy: 99.89%\n",
            "valid accuracy: 86.08%\n",
            "Time elapsed: 1.74 min\n",
            "Epoch: 008/015 | Batch 000/313 | Cost: 0.0019\n",
            "Epoch: 008/015 | Batch 050/313 | Cost: 0.0020\n",
            "Epoch: 008/015 | Batch 100/313 | Cost: 0.0040\n",
            "Epoch: 008/015 | Batch 150/313 | Cost: 0.0044\n",
            "Epoch: 008/015 | Batch 200/313 | Cost: 0.0099\n",
            "Epoch: 008/015 | Batch 250/313 | Cost: 0.0110\n",
            "Epoch: 008/015 | Batch 300/313 | Cost: 0.0012\n",
            "training accuracy: 99.92%\n",
            "valid accuracy: 86.10%\n",
            "Time elapsed: 1.99 min\n",
            "Epoch: 009/015 | Batch 000/313 | Cost: 0.0115\n",
            "Epoch: 009/015 | Batch 050/313 | Cost: 0.0398\n",
            "Epoch: 009/015 | Batch 100/313 | Cost: 0.0049\n",
            "Epoch: 009/015 | Batch 150/313 | Cost: 0.0074\n",
            "Epoch: 009/015 | Batch 200/313 | Cost: 0.0061\n",
            "Epoch: 009/015 | Batch 250/313 | Cost: 0.0081\n",
            "Epoch: 009/015 | Batch 300/313 | Cost: 0.0198\n",
            "training accuracy: 99.89%\n",
            "valid accuracy: 85.80%\n",
            "Time elapsed: 2.24 min\n",
            "Epoch: 010/015 | Batch 000/313 | Cost: 0.0121\n",
            "Epoch: 010/015 | Batch 050/313 | Cost: 0.0027\n",
            "Epoch: 010/015 | Batch 100/313 | Cost: 0.0400\n",
            "Epoch: 010/015 | Batch 150/313 | Cost: 0.0061\n",
            "Epoch: 010/015 | Batch 200/313 | Cost: 0.0013\n",
            "Epoch: 010/015 | Batch 250/313 | Cost: 0.0199\n",
            "Epoch: 010/015 | Batch 300/313 | Cost: 0.0012\n",
            "training accuracy: 99.93%\n",
            "valid accuracy: 86.16%\n",
            "Time elapsed: 2.49 min\n",
            "Epoch: 011/015 | Batch 000/313 | Cost: 0.0041\n",
            "Epoch: 011/015 | Batch 050/313 | Cost: 0.0016\n",
            "Epoch: 011/015 | Batch 100/313 | Cost: 0.0014\n",
            "Epoch: 011/015 | Batch 150/313 | Cost: 0.0026\n",
            "Epoch: 011/015 | Batch 200/313 | Cost: 0.0006\n",
            "Epoch: 011/015 | Batch 250/313 | Cost: 0.0027\n",
            "Epoch: 011/015 | Batch 300/313 | Cost: 0.0035\n",
            "training accuracy: 99.94%\n",
            "valid accuracy: 85.98%\n",
            "Time elapsed: 2.74 min\n",
            "Epoch: 012/015 | Batch 000/313 | Cost: 0.0050\n",
            "Epoch: 012/015 | Batch 050/313 | Cost: 0.0391\n",
            "Epoch: 012/015 | Batch 100/313 | Cost: 0.0030\n",
            "Epoch: 012/015 | Batch 150/313 | Cost: 0.0140\n",
            "Epoch: 012/015 | Batch 200/313 | Cost: 0.0042\n",
            "Epoch: 012/015 | Batch 250/313 | Cost: 0.0012\n",
            "Epoch: 012/015 | Batch 300/313 | Cost: 0.0215\n",
            "training accuracy: 99.96%\n",
            "valid accuracy: 85.48%\n",
            "Time elapsed: 2.99 min\n",
            "Epoch: 013/015 | Batch 000/313 | Cost: 0.0021\n",
            "Epoch: 013/015 | Batch 050/313 | Cost: 0.0017\n",
            "Epoch: 013/015 | Batch 100/313 | Cost: 0.0025\n",
            "Epoch: 013/015 | Batch 150/313 | Cost: 0.0010\n",
            "Epoch: 013/015 | Batch 200/313 | Cost: 0.0005\n",
            "Epoch: 013/015 | Batch 250/313 | Cost: 0.0036\n",
            "Epoch: 013/015 | Batch 300/313 | Cost: 0.0027\n",
            "training accuracy: 99.97%\n",
            "valid accuracy: 86.04%\n",
            "Time elapsed: 3.24 min\n",
            "Epoch: 014/015 | Batch 000/313 | Cost: 0.0009\n",
            "Epoch: 014/015 | Batch 050/313 | Cost: 0.0152\n",
            "Epoch: 014/015 | Batch 100/313 | Cost: 0.1213\n",
            "Epoch: 014/015 | Batch 150/313 | Cost: 0.0144\n",
            "Epoch: 014/015 | Batch 200/313 | Cost: 0.0111\n",
            "Epoch: 014/015 | Batch 250/313 | Cost: 0.0037\n",
            "Epoch: 014/015 | Batch 300/313 | Cost: 0.0657\n",
            "training accuracy: 88.92%\n",
            "valid accuracy: 78.04%\n",
            "Time elapsed: 3.49 min\n",
            "Epoch: 015/015 | Batch 000/313 | Cost: 0.4866\n",
            "Epoch: 015/015 | Batch 050/313 | Cost: 0.3498\n",
            "Epoch: 015/015 | Batch 100/313 | Cost: 0.0216\n",
            "Epoch: 015/015 | Batch 150/313 | Cost: 0.0026\n",
            "Epoch: 015/015 | Batch 200/313 | Cost: 0.0044\n",
            "Epoch: 015/015 | Batch 250/313 | Cost: 0.0041\n",
            "Epoch: 015/015 | Batch 300/313 | Cost: 0.0023\n",
            "training accuracy: 99.88%\n",
            "valid accuracy: 86.28%\n",
            "Time elapsed: 3.73 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppDhqFXvblpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "206d2f1f-7918-4be0-a97e-e5707dbd178d"
      },
      "source": [
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "#prints the confusion matrix as well as test = True\n",
        "print(f'Test accuracy: {compute_accuracy_and_confusion_matrix(model, test_iterator, device,test=True):.2f}%')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Training Time: 3.73 min\n",
            "Confusion Matrix\n",
            "[[10723  1777]\n",
            " [ 1938 10562]]\n",
            "Test accuracy: 85.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoIMCsSQvva4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy \n",
        "nlp = spacy.load('en')\n",
        "def predict_sentiment(model, sentence):\n",
        "    \"\"\" inputs the sentence and the model and outputs the sentiment of sentence based on the model\"\"\"\n",
        "    model.eval()\n",
        "    tokenized = [token.text for token in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.sigmoid(model(tensor,length_tensor))\n",
        "    if (prediction.item())>=0.5:\n",
        "        return \"Positive with score \"+ str(prediction.item())\n",
        "    else:\n",
        "        return \"Negative with score \"+ str(prediction.item())\n",
        "        "
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4hLReu0wxL9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f6956bf-d87a-4c8b-dd15-8873e14df6ed"
      },
      "source": [
        "predict_sentiment(model, \"I really love this movie.This movie is so great!\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive with score 0.9962443113327026'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}